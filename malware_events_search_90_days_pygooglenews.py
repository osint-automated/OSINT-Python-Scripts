"""
Global Malware Monitor
Searches globally for news articles about malware campaigns and related malicious software activity
from the last 90 days. Uses pygooglenews and saves results to a CSV file.
"""

# --- Compatibility fix for Python 3.10+ and pygooglenews / feedparser ---
import collections
if not hasattr(collections, "Callable"):
    import collections.abc
    collections.Callable = collections.abc.Callable
# ------------------------------------------------------------------------

from pygooglenews import GoogleNews
from datetime import datetime, timedelta
import pandas as pd
from bs4 import BeautifulSoup
import feedparser
import dateparser

# Register dateparser as a date handler for feedparser
def dateparser_tuple(date_string):
    dt_object = dateparser.parse(date_string)
    if dt_object:
        return dt_object.utctimetuple()
    return None

feedparser.registerDateHandler(dateparser_tuple)

WINDOW_DAYS = 90

def clean_html(raw_html):
    """Remove HTML tags and trim extra whitespace."""
    if not raw_html:
        return ""
    soup = BeautifulSoup(raw_html, "html.parser")
    return soup.get_text().strip()

def build_malware_query(sector):
    """Build a global malware-related search query."""
    keywords = [
        '"malware campaign"',
        '"malicious software"',
        '"malware infection"',
        '"malware outbreak"',
        '"malicious campaign"',
        '"botnet activity"',
        '"ransomware"',
        '"trojan"',
        '"remote access trojan"',
        '"malicious payload"',
        '"malware distribution"',
    ]
    sector = sector.strip()
    return "(" + " OR ".join(keywords) + f") {sector}" if sector else "(" + " OR ".join(keywords) + ")"

def search_recent_news(sector=""):
    """Search Google News globally for malware articles in the last 90 days."""
    query = build_malware_query(sector)
    cutoff_date = datetime.utcnow() - timedelta(days=WINDOW_DAYS)
    all_articles = []

    print(f"\nSearching globally for '{query}'...")
    gn = GoogleNews(lang="en")  # Global search

    try:
        search_results = gn.search(query)
        entries = search_results.get("entries", [])

        if not entries:
            print("No direct matches, retrying with broader 'malware' query...")
            fallback_query = f'"malware" {sector}'
            search_results = gn.search(fallback_query)
            entries = search_results.get("entries", [])

        if not entries:
            print("No articles found globally for the provided sector and timeframe.")
            return

        for item in entries:
            title = getattr(item, "title", "") or ""
            description = getattr(item, "summary", "") or getattr(item, "description", "") or ""
            clean_description = clean_html(description)

            published_date = None
            if hasattr(item, "published_parsed") and item.published_parsed:
                published_date = datetime(*item.published_parsed[:6])
            elif hasattr(item, "updated_parsed") and item.updated_parsed:
                published_date = datetime(*item.updated_parsed[:6])
            else:
                published_date = dateparser.parse(getattr(item, "published", "") or getattr(item, "updated", ""))

            if not published_date or published_date < cutoff_date:
                continue

            source = ""
            if hasattr(item, "source") and item.source:
                if isinstance(item.source, dict):
                    source = item.source.get("title", "")
                else:
                    source = str(item.source)

            all_articles.append({
                "Source": source,
                "Date": published_date,
                "Title": title,
                "Description": clean_description,
                "Link": getattr(item, "link", "")
            })

        print(f"Fetched {len(entries)} total; retained {len(all_articles)} after 90-day filtering.")

    except Exception as e:
        print(f"An error occurred during global search: {e}")
        return

    if not all_articles:
        print("\nNo recent malware articles found for the specified sector.")
        return

    df = pd.DataFrame(all_articles)
    df["Date"] = pd.to_datetime(df["Date"], errors="coerce", utc=True)
    df = df.sort_values("Date", ascending=False)
    df = df.drop_duplicates(subset=["Title", "Link"], keep="first")

    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    sector_safe = sector.replace(" ", "_") if sector else "global"
    csv_filename = f"malware_global_news_{sector_safe}_{timestamp}.csv"
    df.to_csv(csv_filename, index=False, encoding="utf-8-sig")
    print(f"\nSaved {len(df)} unique articles to '{csv_filename}'")

    # Preview results
    print("\n--- Results Preview ---")
    for _, row in df.iterrows():
        print(f"Date: {row['Date']}")
        print(f"Source: {row['Source']}")
        print(f"Title: {row['Title']}")
        print(f"Description: {row['Description'][:200]}...")
        print(f"Link: {row['Link']}")
        print("-" * 80)

if __name__ == "__main__":
    sector_input = input("Enter the sector to monitor malware activity (e.g., healthcare, finance, energy): ").strip()
    search_recent_news(sector_input)
